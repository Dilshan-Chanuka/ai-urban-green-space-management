{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45c7ac4b-b30f-4b84-a395-661c6348ecbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS ml_project.bronze;\n",
    "CREATE SCHEMA IF NOT EXISTS ml_project.silver;\n",
    "CREATE SCHEMA IF NOT EXISTS ml_project.gold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3600cd-fc08-4222-b4f2-5d925700d744",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"recommendations\":1500},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753726746470}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"recommendations\":1500},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753726733867}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODULE 4: INTELLIGENT RECOMMENDATION ENGINE\n",
    "# Urban Green Space Management System - Improved Version\n",
    "# =============================================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, lit, concat_ws, array, filter as spark_filter, \n",
    "    expr, coalesce, round as spark_round, desc, asc, \n",
    "    collect_list, struct, explode\n",
    ")\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== URBAN GREEN SPACE MANAGEMENT SYSTEM ===\")\n",
    "print(\"Module 4: Intelligent Recommendation Engine (Improved)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. INITIALIZATION AND DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"UGSM_Recommendations_Improved\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configuration\n",
    "CATALOG = \"ml_project\"\n",
    "SILVER_SCHEMA = \"silver\"\n",
    "GOLD_SCHEMA = \"gold\"\n",
    "\n",
    "def load_data_for_recommendations():\n",
    "    \"\"\"Load all necessary data for generating recommendations\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä Loading data for recommendation engine...\")\n",
    "    \n",
    "    try:\n",
    "        # Load processed features\n",
    "        features_df = spark.read.table(f\"{CATALOG}.{SILVER_SCHEMA}.processed_features\")\n",
    "        print(f\"  ‚úÖ Loaded processed features: {features_df.count()} parks\")\n",
    "        \n",
    "        # Load ML predictions if available\n",
    "        try:\n",
    "            predictions_df = spark.read.table(f\"{CATALOG}.{GOLD_SCHEMA}.urban_green_space_model_ce\")\n",
    "            print(f\"  ‚úÖ Loaded ML predictions: {predictions_df.count()} predictions\")\n",
    "            \n",
    "            # Join features with predictions\n",
    "            combined_df = features_df.join(predictions_df, \"park_id\", \"left\")\n",
    "            \n",
    "        except Exception as pred_error:\n",
    "            print(f\"  ‚ö†Ô∏è  ML predictions not available: {str(pred_error)}\")\n",
    "            print(\"  üîÑ Creating default predictions...\")\n",
    "            \n",
    "            # Create default predictions based on business rules\n",
    "            combined_df = features_df.withColumn(\n",
    "                \"intervention_pred\", \n",
    "                when((col(\"avg_aqi\") > 75) & (col(\"avg_sentiment\") < 0), 1).otherwise(0)\n",
    "            ).withColumn(\n",
    "                \"intervention_probability\", \n",
    "                when((col(\"avg_aqi\") > 75) & (col(\"avg_sentiment\") < 0), 0.8).otherwise(0.3)\n",
    "            )\n",
    "        \n",
    "        print(f\"  ‚úÖ Combined dataset ready: {combined_df.count()} parks\")\n",
    "        return combined_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# =============================================================================\n",
    "# 2. ENHANCED RECOMMENDATION LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "class IntelligentRecommendationEngine:\n",
    "    \"\"\"Advanced recommendation engine with multiple recommendation types\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Enhanced thresholds with multiple severity levels\n",
    "        self.thresholds = {\n",
    "            'aqi': {'critical': 120, 'high': 100, 'moderate': 75, 'good': 50},\n",
    "            'footfall': {'very_high': 1500, 'high': 1000, 'moderate': 500, 'low': 100},\n",
    "            'sentiment': {'very_negative': -0.3, 'negative': -0.1, 'neutral': 0.1, 'positive': 0.3},\n",
    "            'area_efficiency': {'low': 1.0, 'moderate': 3.0, 'high': 6.0},\n",
    "            'engagement': {'low': 5.0, 'moderate': 15.0, 'high': 30.0}\n",
    "        }\n",
    "        \n",
    "        # Comprehensive recommendation templates\n",
    "        self.recommendations = {\n",
    "            'air_quality': {\n",
    "                'critical': \"üö® URGENT: Install air purification systems and increase tree planting by 50%\",\n",
    "                'high': \"üå≥ Plant additional air-purifying trees (e.g., Oak, Pine) and monitor pollution sources\",\n",
    "                'moderate': \"üåø Increase green cover and consider installing air quality monitors\",\n",
    "                'maintenance': \"üîß Regular maintenance of existing vegetation for optimal air purification\"\n",
    "            },\n",
    "            'usage_management': {\n",
    "                'very_high': \"üèóÔ∏è Expand facilities, add crowd management systems, and create overflow areas\",\n",
    "                'high': \"üöß Upgrade infrastructure, add more seating, and improve path capacity\",\n",
    "                'low': \"üé™ Organize community events, improve marketing, and enhance park attractiveness\",\n",
    "                'seasonal': \"üìÖ Implement seasonal programming and weather-appropriate activities\"\n",
    "            },\n",
    "            'community_engagement': {\n",
    "                'very_negative': \"ü§ù Launch immediate community consultation and address specific complaints\",\n",
    "                'negative': \"üì¢ Implement feedback system and community improvement programs\", \n",
    "                'positive': \"üéâ Leverage positive sentiment for community advocacy and expansion\",\n",
    "                'social_media': \"üì± Enhance social media presence and community communication\"\n",
    "            },\n",
    "            'operational': {\n",
    "                'efficiency': \"‚ö° Optimize resource allocation based on usage patterns\",\n",
    "                'maintenance': \"üîß Implement predictive maintenance schedules\",\n",
    "                'staffing': \"üë• Adjust staffing levels based on peak usage times\",\n",
    "                'technology': \"üìä Deploy IoT sensors for real-time monitoring\"\n",
    "            },\n",
    "            'accessibility': {\n",
    "                'infrastructure': \"‚ôø Improve accessibility with ramps, wider paths, and accessible facilities\",\n",
    "                'signage': \"üó∫Ô∏è Install multilingual signage and wayfinding systems\",\n",
    "                'transportation': \"üöå Enhance public transportation connections\"\n",
    "            },\n",
    "            'environmental': {\n",
    "                'biodiversity': \"ü¶ã Create wildlife corridors and native plant gardens\",\n",
    "                'water': \"üíß Install rainwater harvesting and sustainable irrigation systems\",\n",
    "                'energy': \"‚ö° Add solar lighting and renewable energy infrastructure\",\n",
    "                'waste': \"‚ôªÔ∏è Implement comprehensive recycling and composting programs\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_park_conditions(self, park_row):\n",
    "        \"\"\"Analyze individual park conditions and generate priority scores\"\"\"\n",
    "        \n",
    "        conditions = {\n",
    "            'air_quality_priority': 0,\n",
    "            'usage_priority': 0, \n",
    "            'sentiment_priority': 0,\n",
    "            'efficiency_priority': 0,\n",
    "            'overall_priority': 0\n",
    "        }\n",
    "        \n",
    "        # Air Quality Analysis\n",
    "        aqi = park_row.get('avg_aqi', 50)\n",
    "        if aqi >= self.thresholds['aqi']['critical']:\n",
    "            conditions['air_quality_priority'] = 5\n",
    "        elif aqi >= self.thresholds['aqi']['high']:\n",
    "            conditions['air_quality_priority'] = 4\n",
    "        elif aqi >= self.thresholds['aqi']['moderate']:\n",
    "            conditions['air_quality_priority'] = 3\n",
    "        elif aqi >= self.thresholds['aqi']['good']:\n",
    "            conditions['air_quality_priority'] = 2\n",
    "        else:\n",
    "            conditions['air_quality_priority'] = 1\n",
    "        \n",
    "        # Usage Pattern Analysis\n",
    "        footfall = park_row.get('total_footfall', 100)\n",
    "        if footfall >= self.thresholds['footfall']['very_high']:\n",
    "            conditions['usage_priority'] = 5\n",
    "        elif footfall >= self.thresholds['footfall']['high']:\n",
    "            conditions['usage_priority'] = 4\n",
    "        elif footfall >= self.thresholds['footfall']['moderate']:\n",
    "            conditions['usage_priority'] = 3\n",
    "        elif footfall >= self.thresholds['footfall']['low']:\n",
    "            conditions['usage_priority'] = 2\n",
    "        else:\n",
    "            conditions['usage_priority'] = 5  # Low usage also needs attention\n",
    "        \n",
    "        # Sentiment Analysis\n",
    "        sentiment = park_row.get('avg_sentiment', 0)\n",
    "        if sentiment <= self.thresholds['sentiment']['very_negative']:\n",
    "            conditions['sentiment_priority'] = 5\n",
    "        elif sentiment <= self.thresholds['sentiment']['negative']:\n",
    "            conditions['sentiment_priority'] = 4\n",
    "        elif sentiment <= self.thresholds['sentiment']['neutral']:\n",
    "            conditions['sentiment_priority'] = 2\n",
    "        else:\n",
    "            conditions['sentiment_priority'] = 1\n",
    "        \n",
    "        # Efficiency Analysis\n",
    "        efficiency = park_row.get('area_efficiency', 2.0)\n",
    "        if efficiency <= self.thresholds['area_efficiency']['low']:\n",
    "            conditions['efficiency_priority'] = 4\n",
    "        elif efficiency <= self.thresholds['area_efficiency']['moderate']:\n",
    "            conditions['efficiency_priority'] = 2\n",
    "        else:\n",
    "            conditions['efficiency_priority'] = 1\n",
    "        \n",
    "        # Calculate overall priority (weighted average)\n",
    "        weights = {\n",
    "            'air_quality_priority': 0.3,\n",
    "            'usage_priority': 0.25,\n",
    "            'sentiment_priority': 0.25,\n",
    "            'efficiency_priority': 0.2\n",
    "        }\n",
    "        \n",
    "        conditions['overall_priority'] = sum(\n",
    "            conditions[key] * weights[key] for key in weights\n",
    "        )\n",
    "        \n",
    "        return conditions\n",
    "    \n",
    "    def generate_comprehensive_recommendations(self, park_row, conditions):\n",
    "        \"\"\"Generate comprehensive recommendations based on park analysis\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Air Quality Recommendations\n",
    "        aqi = park_row.get('avg_aqi', 50)\n",
    "        if aqi >= self.thresholds['aqi']['critical']:\n",
    "            recommendations.append(self.recommendations['air_quality']['critical'])\n",
    "            recommendations.append(self.recommendations['environmental']['energy'])\n",
    "        elif aqi >= self.thresholds['aqi']['high']:\n",
    "            recommendations.append(self.recommendations['air_quality']['high'])\n",
    "            recommendations.append(self.recommendations['environmental']['biodiversity'])\n",
    "        elif aqi >= self.thresholds['aqi']['moderate']:\n",
    "            recommendations.append(self.recommendations['air_quality']['moderate'])\n",
    "        \n",
    "        # Usage Management Recommendations\n",
    "        footfall = park_row.get('total_footfall', 100)\n",
    "        if footfall >= self.thresholds['footfall']['very_high']:\n",
    "            recommendations.append(self.recommendations['usage_management']['very_high'])\n",
    "            recommendations.append(self.recommendations['operational']['staffing'])\n",
    "        elif footfall >= self.thresholds['footfall']['high']:\n",
    "            recommendations.append(self.recommendations['usage_management']['high'])\n",
    "            recommendations.append(self.recommendations['operational']['efficiency'])\n",
    "        elif footfall < self.thresholds['footfall']['low']:\n",
    "            recommendations.append(self.recommendations['usage_management']['low'])\n",
    "            recommendations.append(self.recommendations['community_engagement']['social_media'])\n",
    "        \n",
    "        # Community Engagement Recommendations\n",
    "        sentiment = park_row.get('avg_sentiment', 0)\n",
    "        if sentiment <= self.thresholds['sentiment']['very_negative']:\n",
    "            recommendations.append(self.recommendations['community_engagement']['very_negative'])\n",
    "            recommendations.append(self.recommendations['accessibility']['signage'])\n",
    "        elif sentiment <= self.thresholds['sentiment']['negative']:\n",
    "            recommendations.append(self.recommendations['community_engagement']['negative'])\n",
    "        elif sentiment >= self.thresholds['sentiment']['positive']:\n",
    "            recommendations.append(self.recommendations['community_engagement']['positive'])\n",
    "        \n",
    "        # Operational Efficiency Recommendations\n",
    "        efficiency = park_row.get('area_efficiency', 2.0)\n",
    "        if efficiency <= self.thresholds['area_efficiency']['low']:\n",
    "            recommendations.append(self.recommendations['operational']['efficiency'])\n",
    "            recommendations.append(self.recommendations['operational']['technology'])\n",
    "        \n",
    "        # ML-based Recommendations (if predictions available)\n",
    "        if park_row.get('intervention_pred', 0) == 1:\n",
    "            probability = park_row.get('intervention_probability', 0.5)\n",
    "            if probability > 0.8:\n",
    "                recommendations.append(\"üî• HIGH PRIORITY: Immediate intervention required based on ML analysis\")\n",
    "            elif probability > 0.6:\n",
    "                recommendations.append(\"‚ö†Ô∏è MEDIUM PRIORITY: Consider preventive measures based on ML analysis\")\n",
    "        \n",
    "        # Environmental Sustainability Recommendations\n",
    "        if park_row.get('area_sqm', 0) > 100000:  # Large parks\n",
    "            recommendations.append(self.recommendations['environmental']['water'])\n",
    "            recommendations.append(self.recommendations['environmental']['waste'])\n",
    "        \n",
    "        # Remove duplicates and limit to top recommendations\n",
    "        unique_recommendations = list(dict.fromkeys(recommendations))\n",
    "        return unique_recommendations[:5]  # Top 5 recommendations\n",
    "\n",
    "def create_recommendation_dataframe(df):\n",
    "    \"\"\"Create comprehensive recommendations using Spark operations\"\"\"\n",
    "    \n",
    "    print(\"\\nüß† Generating intelligent recommendations...\")\n",
    "    \n",
    "    engine = IntelligentRecommendationEngine()\n",
    "    \n",
    "    # Convert to Pandas for complex analysis, then back to Spark\n",
    "    df_pandas = df.toPandas()\n",
    "    \n",
    "    # Generate recommendations for each park\n",
    "    recommendation_data = []\n",
    "    \n",
    "    for _, park_row in df_pandas.iterrows():\n",
    "        # Analyze park conditions\n",
    "        conditions = engine.analyze_park_conditions(park_row.to_dict())\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = engine.generate_comprehensive_recommendations(\n",
    "            park_row.to_dict(), conditions\n",
    "        )\n",
    "        \n",
    "        # Create priority level\n",
    "        priority_score = conditions['overall_priority']\n",
    "        if priority_score >= 4:\n",
    "            priority_level = \"CRITICAL\"\n",
    "        elif priority_score >= 3:\n",
    "            priority_level = \"HIGH\"\n",
    "        elif priority_score >= 2:\n",
    "            priority_level = \"MEDIUM\"\n",
    "        else:\n",
    "            priority_level = \"LOW\"\n",
    "        \n",
    "        recommendation_data.append({\n",
    "            'park_id': park_row['park_id'],\n",
    "            'name': park_row.get('name', 'Unknown'),\n",
    "            'city': park_row.get('city', 'Unknown'),\n",
    "            'priority_level': priority_level,\n",
    "            'priority_score': round(priority_score, 2),\n",
    "            'air_quality_priority': conditions['air_quality_priority'],\n",
    "            'usage_priority': conditions['usage_priority'],\n",
    "            'sentiment_priority': conditions['sentiment_priority'],\n",
    "            'efficiency_priority': conditions['efficiency_priority'],\n",
    "            'recommendations': ' | '.join(recommendations) if recommendations else 'No specific recommendations',\n",
    "            'total_recommendations': len(recommendations),\n",
    "            'intervention_required': park_row.get('intervention_pred', 0),\n",
    "            'ml_confidence': round(park_row.get('intervention_probability', 0.5), 3)\n",
    "        })\n",
    "    \n",
    "    # Convert back to Spark DataFrame\n",
    "    recommendations_df = spark.createDataFrame(pd.DataFrame(recommendation_data))\n",
    "    \n",
    "    print(f\"  ‚úÖ Generated recommendations for {len(recommendation_data)} parks\")\n",
    "    \n",
    "    display(recommendations_df)\n",
    "\n",
    "    recommendations_df.write.mode(\"overwrite\") \\\n",
    "        .saveAsTable(f\"{CATALOG}.{GOLD_SCHEMA}.recommendations\")\n",
    "    \n",
    "    return recommendations_df\n",
    "\n",
    "def create_priority_matrix_recommendations(df):\n",
    "    \"\"\"Create simplified recommendations using Spark SQL for better performance\"\"\"\n",
    "    \n",
    "    print(\"\\n‚ö° Creating optimized recommendations using Spark SQL...\")\n",
    "    \n",
    "    # Register the DataFrame as a temporary view\n",
    "    df.createOrReplaceTempView(\"parks_analysis\")\n",
    "    \n",
    "    # Enhanced SQL-based recommendation logic\n",
    "    recommendations_sql = \"\"\"\n",
    "    SELECT \n",
    "        park_id,\n",
    "        name,\n",
    "        city,\n",
    "        avg_aqi,\n",
    "        total_footfall,\n",
    "        avg_sentiment,\n",
    "        intervention_pred,\n",
    "        intervention_probability,\n",
    "        \n",
    "        -- Priority Scoring\n",
    "        CASE \n",
    "            WHEN avg_aqi > 120 OR avg_sentiment < -0.3 OR intervention_probability > 0.8 THEN 'CRITICAL'\n",
    "            WHEN avg_aqi > 100 OR total_footfall > 1000 OR avg_sentiment < -0.1 OR intervention_probability > 0.6 THEN 'HIGH'\n",
    "            WHEN avg_aqi > 75 OR total_footfall < 100 OR intervention_probability > 0.4 THEN 'MEDIUM'\n",
    "            ELSE 'LOW'\n",
    "        END as priority_level,\n",
    "        \n",
    "        -- Comprehensive Recommendations\n",
    "        concat_ws(' | ', \n",
    "            filter(\n",
    "                array(\n",
    "                    CASE WHEN avg_aqi > 120 THEN 'üö® URGENT: Install air purification systems and increase tree planting by 50%'\n",
    "                         WHEN avg_aqi > 100 THEN 'üå≥ Plant additional air-purifying trees and monitor pollution sources'\n",
    "                         WHEN avg_aqi > 75 THEN 'üåø Increase green cover and install air quality monitors'\n",
    "                         ELSE NULL END,\n",
    "                    \n",
    "                    CASE WHEN total_footfall > 1500 THEN 'üèóÔ∏è Expand facilities and add crowd management systems'\n",
    "                         WHEN total_footfall > 1000 THEN 'üöß Upgrade infrastructure and improve path capacity'\n",
    "                         WHEN total_footfall < 100 THEN 'üé™ Organize community events and improve marketing'\n",
    "                         ELSE NULL END,\n",
    "                    \n",
    "                    CASE WHEN avg_sentiment < -0.3 THEN 'ü§ù Launch immediate community consultation'\n",
    "                         WHEN avg_sentiment < -0.1 THEN 'üì¢ Implement feedback system and improvement programs'\n",
    "                         WHEN avg_sentiment > 0.3 THEN 'üéâ Leverage positive sentiment for community advocacy'\n",
    "                         ELSE NULL END,\n",
    "                    \n",
    "                    CASE WHEN intervention_pred = 1 AND intervention_probability > 0.8 THEN 'üî• HIGH PRIORITY: Immediate intervention required (ML Analysis)'\n",
    "                         WHEN intervention_pred = 1 AND intervention_probability > 0.6 THEN '‚ö†Ô∏è MEDIUM PRIORITY: Consider preventive measures (ML Analysis)'\n",
    "                         ELSE NULL END,\n",
    "                    \n",
    "                    CASE WHEN area_sqm > 200000 THEN 'üíß Install sustainable water management systems'\n",
    "                         WHEN area_efficiency < 1.0 THEN '‚ö° Optimize resource allocation and improve efficiency'\n",
    "                         ELSE NULL END\n",
    "                ), \n",
    "                x -> x IS NOT NULL\n",
    "            )\n",
    "        ) as recommendations,\n",
    "        \n",
    "        -- Additional Metrics\n",
    "        CASE WHEN avg_aqi > 100 THEN 5\n",
    "             WHEN avg_aqi > 75 THEN 3\n",
    "             ELSE 1 END +\n",
    "        CASE WHEN total_footfall > 1000 OR total_footfall < 100 THEN 3\n",
    "             ELSE 1 END +\n",
    "        CASE WHEN avg_sentiment < -0.1 THEN 4\n",
    "             WHEN avg_sentiment < 0.1 THEN 2\n",
    "             ELSE 1 END as priority_score\n",
    "        \n",
    "    FROM parks_analysis\n",
    "    ORDER BY priority_score DESC, intervention_probability DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    recommendations_df = spark.sql(recommendations_sql)\n",
    "    \n",
    "    print(f\"  ‚úÖ SQL-based recommendations generated successfully\")\n",
    "    \n",
    "    return recommendations_df\n",
    "\n",
    "# =============================================================================\n",
    "# 3. EXECUTE RECOMMENDATION GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load data\n",
    "combined_df = load_data_for_recommendations()\n",
    "\n",
    "# Generate recommendations using both approaches\n",
    "print(\"\\nüîÑ Generating recommendations using multiple approaches...\")\n",
    "\n",
    "# Approach 1: Comprehensive Python-based recommendations\n",
    "try:\n",
    "    comprehensive_recommendations = create_recommendation_dataframe(combined_df)\n",
    "    print(\"‚úÖ Comprehensive recommendations generated\")\n",
    "except Exception as comp_error:\n",
    "    print(f\"‚ö†Ô∏è Comprehensive approach failed: {str(comp_error)}\")\n",
    "    comprehensive_recommendations = None\n",
    "\n",
    "# Approach 2: Optimized SQL-based recommendations (fallback)\n",
    "try:\n",
    "    sql_recommendations = create_priority_matrix_recommendations(combined_df)\n",
    "    print(\"‚úÖ SQL-based recommendations generated\")\n",
    "except Exception as sql_error:\n",
    "    print(f\"‚ùå SQL approach also failed: {str(sql_error)}\")\n",
    "    sql_recommendations = None\n",
    "\n",
    "# Select the best available recommendations\n",
    "final_recommendations = comprehensive_recommendations if comprehensive_recommendations else sql_recommendations\n",
    "\n",
    "# =============================================================================\n",
    "# 4. SAVE RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "\n",
    "def save_recommendations(recommendations_df):\n",
    "    \"\"\"Save recommendations to Spark table\"\"\"\n",
    "    \n",
    "    print(f\"\\nüíæ Saving recommendations...\")\n",
    "    \n",
    "    try:\n",
    "        if recommendations_df is not None:\n",
    "            # Save to the specified table\n",
    "            recommendations_df.write.mode(\"overwrite\") \\\n",
    "                .saveAsTable(f\"{CATALOG}.{GOLD_SCHEMA}.urban_green_space_recommendations_ce\")\n",
    "            \n",
    "            print(f\"‚úÖ Recommendations saved to {CATALOG}.{GOLD_SCHEMA}.urban_green_space_recommendations_ce\")\n",
    "            \n",
    "            # Display sample recommendations\n",
    "            print(f\"\\nüìã Sample Recommendations:\")\n",
    "            sample_display = recommendations_df.select(\n",
    "                \"park_id\", \"name\", \"priority_level\", \"recommendations\"\n",
    "            ).limit(10)\n",
    "            \n",
    "            sample_display.show(truncate=False)\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå No recommendations available to save\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as save_error:\n",
    "        print(f\"‚ùå Error saving recommendations: {str(save_error)}\")\n",
    "        return False\n",
    "\n",
    "# Save recommendations\n",
    "if final_recommendations:\n",
    "    save_recommendations(final_recommendations)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. GENERATE RECOMMENDATION ANALYTICS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_recommendation_analytics(recommendations_df):\n",
    "    \"\"\"Generate analytics and insights from recommendations\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä RECOMMENDATION ANALYTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        if recommendations_df is None:\n",
    "            print(\"‚ùå No recommendations available for analysis\")\n",
    "            return\n",
    "        \n",
    "        # Convert to Pandas for analysis\n",
    "        rec_pandas = recommendations_df.toPandas()\n",
    "        \n",
    "        # Priority Level Distribution\n",
    "        print(f\"üéØ Priority Level Distribution:\")\n",
    "        if 'priority_level' in rec_pandas.columns:\n",
    "            priority_dist = rec_pandas['priority_level'].value_counts().sort_index()\n",
    "            total_parks = len(rec_pandas)\n",
    "            \n",
    "            for level, count in priority_dist.items():\n",
    "                percentage = (count / total_parks) * 100\n",
    "                print(f\"  ‚Ä¢ {level}: {count} parks ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Top Cities Requiring Intervention\n",
    "        print(f\"\\nüèôÔ∏è Top Cities Requiring Attention:\")\n",
    "        if 'city' in rec_pandas.columns and 'priority_level' in rec_pandas.columns:\n",
    "            city_priorities = rec_pandas[rec_pandas['priority_level'].isin(['CRITICAL', 'HIGH'])] \\\n",
    "                .groupby('city').size().sort_values(ascending=False).head(5)\n",
    "            \n",
    "            for city, count in city_priorities.items():\n",
    "                print(f\"  ‚Ä¢ {city}: {count} high-priority parks\")\n",
    "        \n",
    "        # Most Common Recommendation Types\n",
    "        print(f\"\\nüí° Most Common Recommendation Categories:\")\n",
    "        if 'recommendations' in rec_pandas.columns:\n",
    "            # Extract recommendation categories (simplified analysis)\n",
    "            all_recommendations = ' '.join(rec_pandas['recommendations'].fillna('').tolist())\n",
    "            \n",
    "            categories = {\n",
    "                'Air Quality': all_recommendations.count('üå≥') + all_recommendations.count('üåø'),\n",
    "                'Infrastructure': all_recommendations.count('üèóÔ∏è') + all_recommendations.count('üöß'),\n",
    "                'Community': all_recommendations.count('ü§ù') + all_recommendations.count('üì¢'),\n",
    "                'Events': all_recommendations.count('üé™') + all_recommendations.count('üéâ'),\n",
    "                'Technology': all_recommendations.count('üìä') + all_recommendations.count('‚ö°')\n",
    "            }\n",
    "            \n",
    "            sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "            for category, count in sorted_categories[:5]:\n",
    "                if count > 0:\n",
    "                    print(f\"  ‚Ä¢ {category}: {count} mentions\")\n",
    "        \n",
    "        # ML Model Integration Analysis\n",
    "        if 'intervention_required' in rec_pandas.columns and 'ml_confidence' in rec_pandas.columns:\n",
    "            print(f\"\\nü§ñ ML Model Integration:\")\n",
    "            ml_interventions = rec_pandas['intervention_required'].sum()\n",
    "            high_confidence = len(rec_pandas[rec_pandas['ml_confidence'] > 0.7])\n",
    "            print(f\"  ‚Ä¢ Parks flagged by ML model: {ml_interventions}\")\n",
    "            print(f\"  ‚Ä¢ High-confidence predictions: {high_confidence}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Recommendation analytics completed\")\n",
    "        \n",
    "    except Exception as analytics_error:\n",
    "        print(f\"‚ùå Analytics generation failed: {str(analytics_error)}\")\n",
    "\n",
    "# Generate analytics\n",
    "if final_recommendations:\n",
    "    generate_recommendation_analytics(final_recommendations)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. CREATE EXECUTIVE SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "def create_executive_summary(recommendations_df, combined_df):\n",
    "    \"\"\"Create executive summary for stakeholders\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìã EXECUTIVE SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        total_parks = combined_df.count()\n",
    "        \n",
    "        if recommendations_df:\n",
    "            rec_pandas = recommendations_df.toPandas()\n",
    "            \n",
    "            # Key statistics\n",
    "            critical_parks = len(rec_pandas[rec_pandas['priority_level'] == 'CRITICAL'])\n",
    "            high_priority_parks = len(rec_pandas[rec_pandas['priority_level'] == 'HIGH'])\n",
    "            \n",
    "            print(f\"üèûÔ∏è Total Parks Analyzed: {total_parks}\")\n",
    "            print(f\"üö® Critical Priority Parks: {critical_parks}\")\n",
    "            print(f\"‚ö†Ô∏è High Priority Parks: {high_priority_parks}\")\n",
    "            print(f\"üìä Total Recommendations Generated: {len(rec_pandas)}\")\n",
    "            \n",
    "            # Key insights\n",
    "            print(f\"\\nüí° Key Insights:\")\n",
    "            print(f\"  ‚Ä¢ {((critical_parks + high_priority_parks) / total_parks * 100):.1f}% of parks require immediate attention\")\n",
    "            print(f\"  ‚Ä¢ Air quality is the primary concern in urban parks\")\n",
    "            print(f\"  ‚Ä¢ Community engagement initiatives needed in negative sentiment areas\")\n",
    "            print(f\"  ‚Ä¢ Infrastructure upgrades required for high-usage parks\")\n",
    "            \n",
    "            # Action items\n",
    "            print(f\"\\nüéØ Immediate Action Items:\")\n",
    "            print(f\"  1. Address {critical_parks} critical priority parks within 30 days\")\n",
    "            print(f\"  2. Develop improvement plans for {high_priority_parks} high priority parks\")\n",
    "            print(f\"  3. Implement monitoring systems for real-time data collection\")\n",
    "            print(f\"  4. Engage communities in parks with negative sentiment\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Detailed analysis not available - basic summary only\")\n",
    "            print(f\"üèûÔ∏è Total Parks: {total_parks}\")\n",
    "            print(\"üìä Recommendations system operational\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Executive summary generated\")\n",
    "        \n",
    "    except Exception as summary_error:\n",
    "        print(f\"‚ùå Executive summary generation failed: {str(summary_error)}\")\n",
    "\n",
    "# Generate executive summary\n",
    "create_executive_summary(final_recommendations, combined_df)\n",
    "\n",
    "\n",
    "print(f\"\\nüéØ RECOMMENDATION ENGINE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ Intelligent recommendation engine completed successfully\")\n",
    "print(f\"üìä Recommendations saved to: {CATALOG}.{GOLD_SCHEMA}.urban_green_space_recommendations_ce\")\n",
    "print(f\"üß† Advanced analytics and priority scoring implemented\")\n",
    "print(f\"üìã Executive summary generated for stakeholders\")\n",
    "\n",
    "# Display the final recommendations DataFrame\n",
    "display(final_recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0f114e1f-ffdc-421f-a65a-71abce4c7da2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"ml_project.default.urban_green_space_recommendations_ce\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5929969121396212,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Module 4: Intelligent Recommendation Engine",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
