{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d46321f-4da0-448b-830d-ec5d8120055c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### clean_transform_to_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3fb295a-9513-4b3f-a7a6-6ab5e29ae502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, count, when, col, dayofweek, hour, mean\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "foot_df = spark.read.table(\"ml_project.bronze.footfall\")\n",
    "parks_df = spark.read.table(\"ml_project.bronze.parks\")\n",
    "sent_df = spark.read.table(\"ml_project.bronze.sentiment\")\n",
    "aq_df = spark.read.table(\"ml_project.bronze.air_quality\")\n",
    "\n",
    "# Convert the date column to date type\n",
    "aq_df = aq_df.withColumn(\"date\", to_date(col(\"date\"), \"M/d/yyyy\"))\n",
    "\n",
    "# Convert the timestamp column to date type and create new features\n",
    "foot_df = foot_df.withColumn(\"date\", to_date(col(\"timestamp\"))) \\\n",
    "                  .withColumn(\"day_of_week\", dayofweek(col(\"timestamp\"))) \\\n",
    "                  .withColumn(\"hour\", hour(col(\"timestamp\")))\n",
    "\n",
    "# Create a new feature: average visitor count per day of week\n",
    "avg_visitor_count_per_day = foot_df.groupBy(\"day_of_week\").agg(F.mean(\"visitor_count\").alias(\"avg_visitor_count\"))\n",
    "foot_df = foot_df.join(avg_visitor_count_per_day, on=\"day_of_week\", how=\"left\")\n",
    "\n",
    "# Create a new feature: sentiment score per park\n",
    "sentiment_score_per_park = sent_df.groupBy(\"park_id\").agg(F.mean(\"sentiment_score\").alias(\"avg_sentiment_score\"))\n",
    "parks_df = parks_df.join(sentiment_score_per_park, on=\"park_id\", how=\"left\")\n",
    "\n",
    "# Integrate the DataFrames\n",
    "integrated_df = foot_df.join(parks_df, on=\"park_id\", how=\"left\") \\\n",
    "                        .join(aq_df, on=[\"park_id\", \"date\"], how=\"left\") \\\n",
    "                        .join(sent_df, on=[\"park_id\", \"timestamp\"], how=\"left\")\n",
    "\n",
    "# Drop duplicate columns\n",
    "for col_name in integrated_df.columns:\n",
    "    if integrated_df.columns.count(col_name) > 1:\n",
    "        integrated_df = integrated_df.drop(col_name)\n",
    "\n",
    "# # Save the integrated DataFrame as a Delta table\n",
    "integrated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ml_project.silver.integrated\")\n",
    "\n",
    "# Display the DataFrames\n",
    "display(foot_df)\n",
    "display(parks_df)\n",
    "display(integrated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "702c9a7b-2b14-48e1-a4ca-5cedc45631c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the data using plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the DataFrames to Pandas DataFrames\n",
    "foot_df_pd = foot_df.toPandas()\n",
    "sent_df_pd = sent_df.toPandas()\n",
    "aq_df_pd = aq_df.toPandas()\n",
    "\n",
    "# Plot the distribution of visitor_count\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(foot_df_pd['visitor_count'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Visitor Count')\n",
    "plt.xlabel('Visitor Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of sentiment_score\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sent_df_pd['sentiment_score'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Sentiment Score')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the distribution of air quality score (assuming it's in a column named 'aqi' or 'air_quality_score')\n",
    "if 'aqi' in aq_df_pd.columns:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.hist(aq_df_pd['aqi'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title('Distribution of Air Quality Index (AQI)')\n",
    "    plt.xlabel('AQI')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "elif 'air_quality_score' in aq_df_pd.columns:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.hist(aq_df_pd['air_quality_score'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title('Distribution of Air Quality Score')\n",
    "    plt.xlabel('Air Quality Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No air quality score column found in the DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
